{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e83589c",
   "metadata": {},
   "source": [
    "우리가 볼 첫번째 MLOps는 하이퍼파라미터 튜닝입니다. 그중에서 우리가 사용할 툴은 KerasTuner입니다.\n",
    "\n",
    "KerasTuner는 Keras뿐만 아니라 scikit-learn과 같은 모델에서도 커스터마이징해서 사용할 수 있는 툴이며 하이퍼파라미터 튜닝을 자동으로 할 수 있게 도와줍니다.\n",
    "\n",
    "기존 모델에서 하이퍼파라미터 튜닝을 진행한다고 했을 때 딥러닝의 경우 일일이 바꿔가면서 함수를 만들고 정리했습니다. 그러나 KerasTuenr를 사용하고 범위를 결정하는 함수를 잘 선택한다면 하이퍼파라미터 튜닝을 원하는대로 할 수 있습니다.\n",
    "\n",
    "\n",
    "이번 실습은 MNIST로 간단하게 할 수 있는 하이퍼파라미터 튜닝작업입니다!\n",
    "\n",
    "우선 디렉토리 먼저 만들어놓도록 하겠습니다.\n",
    "\n",
    "이번 실습에 앞서 우선 KerasTuner를 설치하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4366ddb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "명령 구문이 올바르지 않습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "     -------------------------------------- 176.1/176.1 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\anaconda3\\envs\\test\\lib\\site-packages (from keras-tuner) (22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\envs\\test\\lib\\site-packages (from keras-tuner) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\envs\\test\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\administrator\\anaconda3\\envs\\test\\lib\\site-packages (from requests->keras-tuner) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\envs\\test\\lib\\site-packages (from requests->keras-tuner) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\administrator\\anaconda3\\envs\\test\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/aiffel/mlops\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2c15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e235a92",
   "metadata": {},
   "source": [
    "우리가 이번에 사용할 데이터셋은 MNIST입니다. keras에 내장되어 있는 datasets으로 불러오겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a0156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374bf177",
   "metadata": {},
   "source": [
    "CNN을 사용할 예정이라 차원 수를 하나 더 추가해줍니다.  \n",
    "또한 label을 categorical을 활용해 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2bf520",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(-1,28, 28, 1) \n",
    "X_test = x_test.reshape(-1,28,28,1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f29699",
   "metadata": {},
   "source": [
    "scikit-learn에 내장되어 있는 train_test_split으로 train data와 validation data를 나누어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbc8278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb382db",
   "metadata": {},
   "source": [
    "이번에는 제가 짠 DeepTuner를 살펴보겠습니다!\n",
    "\n",
    "DeepTuner의 경우 kerastuner.Tuner를 인자로 하는 class이며 class에서 수행하는 함수는 run_trial, save_model load_model입니다.\n",
    "\n",
    "run_trial 함수에서 제일 중요한 부분은 hypermodel과 trial입니다.\n",
    "\n",
    "KerasTuner에서의 hypermodel은 모델을 공유 및 재사용하기 위해 검색 공간을 캡슐화하는 모델입니다. hypermodel의 경우 hp라는 인수를 활용해서 keras.Model을 생성합니다.\n",
    "즉 hypermodel은 우리가 만들고 싶은 모델을 쌓는 과정을 거치는데 이때 하이퍼파라미터 튜닝에 대한 검색공간을 만들어줄때 hp라는 인수를 사용해서 만든 모델입니다.\n",
    "hypermodel의 경우 build 메소드를 활용하면 모델이 빌드가 되면서 하이퍼파라미터 튜닝이 시작합니다.\n",
    "\n",
    "trial의 경우에는 Oracle에 속하는 class입니다.\n",
    "Oracle이란 KerasTuner의 모든 검색 알고리즘에서 사용하는 기본 클래스이며 크게 RandomSearchOracle, BayesianOptimizationOracle, HyperbandOracle이 있습니다.\n",
    "쉽게 설명하면 Oracle은 KerasTuner가 하이퍼파라미터를 정할 때 사용하는 알고리즘이라고 생각하시면 됩니다!\n",
    "여기서 trial.hyperparameter는 Oracle이 찾아야 하는 하이퍼파라미터입니다. 즉 hypermodel에서의 hp입니다.\n",
    "제가 model.fit()을 할때 batch_size도 고를 수 있게 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ffdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X, y, validation_data, **fit_kwargs):\n",
    "        model = self.hypermodel.build(trial.hyperparameters)\n",
    "        model.fit(X, y, batch_size=trial.hyperparameters.Choice(\n",
    "            'batch_size', [16, 32]), **fit_kwargs)\n",
    "\n",
    "\n",
    "        X_val, y_val = validation_data\n",
    "        eval_scores = model.evaluate(X_val, y_val)\n",
    "        return {name: value for name, value in zip(\n",
    "            model.metrics_names,\n",
    "            eval_scores)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df1ecc",
   "metadata": {},
   "source": [
    "이번에는 build_model쪽을 보도록 하겠습니다.\n",
    "\n",
    "build_model은 위에서 설명한것처럼 hypermodel을 만들어줘야 합니다. 제가 만든 hypermodel은 총 2가지 기법이 들어가 있으며 주의사항도 1가지 있습니다.\n",
    "\n",
    "우선 주의사항부터 말씀드리면 해당 모델의 경우 hypermodel이기 때문에 Input지정이 필수입니다!\n",
    "그렇기에 여러분들이 넣고 싶은 모델에 대한 shape을 꼭 기재해주셔야 합니다!\n",
    "\n",
    "제가 사용한 첫번째 기법은 바로 layer의 숫자도 KerasTuner에게 맡겼습니다.\n",
    "for문을 확인해보겠습니다\n",
    "\n",
    "첫번째 for문의 경우 hp.Int로 만들어 검색공간은 정수로 만들고 가장 작은값을 1로 가장 큰값을 10으로 두었습니다.\n",
    "이렇게 설정하면 최소 1개에서 최소 10개의 layer를 쌓을 수 있게 설정할 수 있습니다.\n",
    "\n",
    "제가 쌓고싶은 layer는 conv2D인데 kernel_size는 (3,3)이며 차원수는 최소 32에서 최대 256으로 바꾸었습니다.\n",
    "\n",
    "두번째 for문을 살펴보겠습니다. 두번째 for문도 최소 1개에서 3개로 설정했지만 Dense Layer의 경우 나올 수 있는 차원을 32,64,128,256중 1개를 선택하도록 만들었습니다.\n",
    "\n",
    "이러한 방식으로 hypermodel을 만들면 하고싶은 하이퍼 파라미터 튜닝을 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3088c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape = X_train.shape[1:], name = 'inputs'))\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n",
    "              model.add(tf.keras.layers.Conv2D(hp.Int(\n",
    "                  'units_{i}'.format(i=i), min_value=32, max_value=128, step=5), (3,3),activation='relu'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for i in range(hp.Int('n_connections', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(hp.Choice(f'n_nodes',\n",
    "                                  values=[32,64,128, 256]), activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', name = 'outputs'))\n",
    "    model.compile(optimizer = 'adam',loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b0a7c",
   "metadata": {},
   "source": [
    "마지막으로 keras_tuner를 정의하고 탐색하는것까지 보도록 하겠습니다.\n",
    "\n",
    "저는 이번 모델의 경우 BayesianOptimizationOracle을 사용할 예정이며 목표는 accuracy와 max로 둘 예정입니다. 실제 trial은 10번으로 지정할 것입니다.\n",
    "\n",
    "hypermodel은 build_model을 넣어주시고 project이름도 작성해주세요.\n",
    "\n",
    "마지막으로 search함수에 X_train, Y_train, validation data, epoch을 넣고 탐색합니다!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84afbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 12m 15s]\n",
      "accuracy: 0.9793333411216736\n",
      "\n",
      "Best accuracy So Far: 0.9851666688919067\n",
      "Total elapsed time: 02h 15m 01s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "my_keras_tuner = DeepTuner(\n",
    "    oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "        objective=kt.Objective('accuracy', 'max'),\n",
    "        max_trials=10,\n",
    "        seed=42),\n",
    "    hypermodel=build_model,\n",
    "    overwrite=True,\n",
    "    project_name='my_keras_tuner')\n",
    "\n",
    "# 해당 모델 학습시간은 약 10분정도 걸립니다!\n",
    "my_keras_tuner.search(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f247b9",
   "metadata": {},
   "source": [
    "가장 좋은 모델을 뽑는 방법은 KerasTuner.get_best_hyperparamters를 이용해서 가장 좋은 하이퍼파라미터를 뽑아내는 작업입니다\n",
    "하이퍼파라미터를 뽑았으면 build_model()에 집어넣어 가장 좋은 모델을 선언합니다.\n",
    "\n",
    "그렇다면 여러분들이 만든 가장 좋은 모델을 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6bea370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_65 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 20, 20, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 18, 18, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                401472    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 462,090\n",
      "Trainable params: 462,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hps = my_keras_tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "model = build_model(best_hps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e975c52",
   "metadata": {},
   "source": [
    "최고의 하이퍼 파라미터만 뽑았기 때문에 아직 모델학습이 되지 않았습니다!\n",
    "이번에 epoch을 5번정도 주어서 모델학습을 진행합니다!\n",
    "\n",
    "만일 여러분들이 무거운 모델을 돌릴 경우 하이퍼파라미터 튜닝작업이 매우 느려질 수 있습니다.\n",
    "그때의 경우 하이퍼파라미터 튜닝할때 epoch을 3-4정도로 작게 준 다음 최고의 하이퍼파라미터를 뽑아낸 다음\n",
    "본격적인 모델학습때 epoch을 넉넉하게 주는 것도 방법입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6157a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 137s 90ms/step - loss: 0.1714 - accuracy: 0.9476\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 134s 89ms/step - loss: 0.0662 - accuracy: 0.9801\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 138s 92ms/step - loss: 0.0502 - accuracy: 0.9846\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 135s 90ms/step - loss: 0.0405 - accuracy: 0.9874\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 135s 90ms/step - loss: 0.0311 - accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9b1dea590>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e142e37",
   "metadata": {},
   "source": [
    "모델 평가를 진행해볼까요? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef77c97",
   "metadata": {},
   "source": [
    "이제 모델을 저장할 차례입니다.\n",
    "\n",
    "우리가 이전까지 자주 사용한 저장방법은 HDF5파일 (.h5)로 저장하는 방법이었습니다.\\\n",
    "\n",
    "HDF파일로 저장하는 방식은 이전 Keras에서 모델을 저장하는 방식이었으나 사실 이 방법은 TensorFlow나 Keras에서 그다지 선호하지 않는 저장방식입니다.\\\n",
    "\n",
    "TensorFlow의 경우 공식적으로 지원하는 모델 저장방식은 SavedModel입니다.\n",
    "https://d3s0tskafalll9.cloudfront.net/media/original_images/tree.png  \n",
    "    \n",
    "SavedModel은 .h5파일처럼 모델의 가중치와 모델을 전부 하나의 파일로 관리하는 방식이 아닌 모델, 가중치를 따로 구분해서 저장하는 방식입니다.\n",
    "\n",
    "SavedModel은 크게 3가지로 구성되어 있습니다.\n",
    "\n",
    "- saved_model.pb : pb는 프로토콜 버퍼를 의미하며 해당 파일은 내보낸 모델 그래프 구조를 포함하고 있습니다.\n",
    "- variables : 내보낸 변수값이 있는 이진 파일과 내보낸 모델 그래프에 해당하는 체크포인트를 포함하고 있습니다\n",
    "- assets : 내보낸 모델을 불러올 때 추가적인 파일이 필요한 경우 이 폴더에 파일이 생성됩니다.\n",
    "    \n",
    "이 방식으로 진행한다면 모델을 배포할 때 유리합니다.\n",
    "\n",
    "Keras의 경우 .keras파일을 선호합니다. .keras파일은 .h5파일과 마찬가지로 가중치와 모델을 전부 하나의 파일로 관리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e085ed11",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHOME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/aiffel/mlops/best_model/1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      2\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave(fname)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "save_path = os.getenv('HOME') + '/aiffel/mlops/best_model/1'\n",
    "fname = os.path.join(save_path, 'model')\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddad272",
   "metadata": {},
   "source": [
    "모델을 만들었다면 이제는 배포를 진행해봐야죠!\n",
    "\n",
    "배포를 진행하는 방법은 크게 2가지로 나눌 수 있습니다.\n",
    "\n",
    "- 클라우드를 활용해서 모델을 배포하는 방식\n",
    "- 경량화된 모델을 만들어서 휴대폰같은 디바이스에서도 모델이 실행되게 만드는 방식\n",
    "TensorFlow는 첫번째 방식을 TFServing을 통해서 가능하게 만들며 2번째 방식은 TFLite방식으로 가능하게 만듭니다.\n",
    "\n",
    "## TFServing\n",
    "TFServing이란 텐서플로우 그래프를 배포할 수 있으며 표준화된 엔드포인트를 제공합니다. 또한 모델 및 버전관리가 가능하며 정책 기반으로 모델을 서비스할 수 있습니다.\n",
    "또한 지연 시간이 최대한 짧게 만드는 고성능 처리량에서도 초점을 맞추고 있습니다.\\\n",
    "\n",
    "TFServing을 하는 방식은 크게 2가지가 있습니다.\n",
    "\n",
    "- Docker를 활용한 배포\n",
    "- 우분투 터미널을 활용한 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a30a04",
   "metadata": {},
   "source": [
    "## TFServing Docker로 실습하기\n",
    "Docker를 설치하셨다면\n",
    "docker pull tensorflow/serving  \n",
    "\n",
    "docker run -p 8500:8500 \\\n",
    "\t\t\t-p 8501:8501 \\\n",
    "\t\t\t--mount type=bind, source=/tmp/models, target=/models/my_model\n",
    "\t\t\t-e MODEL_NAME=my_model \\\n",
    "\t\t\t-e MODEL_BASE_PATH=/models/my_model \\\n",
    "\t\t\t-t tensorflow/serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bace9",
   "metadata": {},
   "source": [
    "## TFLite로 경량화 모델 만들기\n",
    "TFLite는 TensorFlow로 만들어진 모델을 휴대폰같은 기기에서도 실행될수 있게 더 작은 모델 크기로 변환해서 배포하는데 사용하게 만드는 방법입니다.\n",
    "TFLite의 경우 양자화라는 기법을 활용해 모델의 크기를 줄이지만 그렇다고 해서 모델의 성능이 크게 저하되지 않습니다.\\\n",
    "\n",
    "TFLite의 경우 TensorFlow에 내장되어 있어 별도의 설치가 없이 작동하는 방식입니다!\n",
    "\n",
    "그렇다면 tflite파일을 만들어보도록 하겠습니다! 첫번째로 아까 만들었던 모델을 불러옵니다!\n",
    "\n",
    "주의사항 현재 LMS에서 tflite모델이 만들어지긴 하지만 원인을 모르겠으나 모바일에서 tflite파일을 구동할때 중요한 '서명'이 지워진 상태로 나오고 있습니다. 그렇기에 실제 프로젝트를 진행할 때는 LMS에서 tflite파일을 만들기보다 Google Colab에서 만드는 것을 추천합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c21236",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHOME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/aiffel/mlops/best_model/model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(load_path)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "load_path = os.getenv('HOME') + '/aiffel/mlops/best_model/model'\n",
    "best_model = tf.keras.models.load_model(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2985d957",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7bfc7",
   "metadata": {},
   "source": [
    "그렇다면 이제 tflite파일로 변환을 진행해보도록 하겠습니다!\n",
    "\n",
    "변환을 진행할 떄에는 tf.lite.TFLiteConverter메소드를 활용하면 쉽게 바꿀 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30bc35c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp7qermwze\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp7qermwze\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f099bb4",
   "metadata": {},
   "source": [
    "tflite파일을 만들어서 우선 보관하도록 하겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39055f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b7a41e",
   "metadata": {},
   "source": [
    "tflite파일이 변환이 잘 되었는지 확인하기 위해 서명부분을 확인해보겠습니다!\n",
    "https://colab.research.google.com/drive/1Uhp4AOLUjvQWVFnsjoloVaSx-_TDJqzi?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e7f667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serving_default': {'inputs': ['inputs'], 'outputs': ['outputs']}}\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "signatures = interpreter.get_signature_list()\n",
    "print(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13047ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.lite.python.interpreter.SignatureRunner at 0x1e9b1c86560>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_lite = interpreter.get_signature_runner('serving_default')\n",
    "classify_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfebb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
